{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b46c6777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: c:\\Users\\It's Blue\\fraud-detection\\notebooks\n",
      "\n",
      "Files in data/ directory:\n",
      "\n",
      "Loading data from: data/Fraud_Data.csv\n",
      "Data loaded: (151112, 11)\n",
      "Features: ['purchase_value', 'age', 'ip_address', 'purchase_hour', 'hours_since_signup', 'quick_purchase']\n",
      "X shape: (151112, 6)\n",
      "y shape: (151112,)\n",
      "Fraud rate: 9.3646%\n",
      "\n",
      "Train set: (120889, 6), fraud rate: 9.3648%\n",
      "Test set: (30223, 6), fraud rate: 9.3637%\n",
      "\n",
      "============================================================\n",
      "1. BASELINE MODEL - LOGISTIC REGRESSION\n",
      "============================================================\n",
      "============================================================\n",
      "BASELINE: Logistic Regression\n",
      "============================================================\n",
      "\n",
      "Results for Logistic Regression:\n",
      "  PR-AUC: 0.2715\n",
      "  ROC-AUC: 0.7117\n",
      "  F1-Score: 0.3035\n",
      "\n",
      "  Confusion Matrix:\n",
      "    TN: 19917, FP: 7476\n",
      "    FN: 986, TP: 1844\n",
      "\n",
      "============================================================\n",
      "2. ENSEMBLE MODEL - RANDOM FOREST\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "ENSEMBLE: RANDOM_FOREST\n",
      "============================================================\n",
      "Performing basic hyperparameter check...\n",
      "  Selected max_depth=5 (PR-AUC: 0.6194)\n",
      "\n",
      "Results for Random Forest:\n",
      "  PR-AUC: 0.6194\n",
      "  ROC-AUC: 0.7644\n",
      "  F1-Score: 0.6900\n",
      "\n",
      "  Confusion Matrix:\n",
      "    TN: 27392, FP: 1\n",
      "    FN: 1339, TP: 1491\n",
      "\n",
      "============================================================\n",
      "3. 5-FOLD CROSS-VALIDATION\n",
      "============================================================\n",
      "\n",
      "5-Fold Cross-Validation for Logistic Regression:\n",
      "  PR-AUC: 0.2760 (¬±0.0057)\n",
      "  F1-Score: 0.3084 (¬±0.0032)\n",
      "\n",
      "5-Fold Cross-Validation for Random Forest:\n",
      "  PR-AUC: 0.6277 (¬±0.0041)\n",
      "  F1-Score: 0.6985 (¬±0.0051)\n",
      "\n",
      "============================================================\n",
      "4. MODEL COMPARISON AND SELECTION\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "MODEL COMPARISON\n",
      "============================================================\n",
      "\n",
      "Model Comparison Table:\n",
      "------------------------------------------------------------\n",
      "              Model   PR-AUC  ROC-AUC  F1-Score\n",
      "      Random Forest 0.619443 0.764410  0.689958\n",
      "Logistic Regression 0.271527 0.711659  0.303539\n",
      "------------------------------------------------------------\n",
      "\n",
      "SELECTED BEST MODEL: Random Forest\n",
      "Justification:\n",
      "  1. Highest PR-AUC (0.6194) - primary metric for imbalanced data\n",
      "  2. Good F1-Score (0.6900) - balance of precision and recall\n",
      "  3. Better at capturing complex patterns\n",
      "\n",
      "============================================================\n",
      "5. SAVE MODEL FOR TASK 3\n",
      "============================================================\n",
      "\n",
      "‚úÖ Model saved: models/random_forest.pkl\n",
      "\n",
      "‚úÖ Best model saved to: models/random_forest.pkl\n",
      "Ready for Task 3: Model Explainability\n",
      "\n",
      "============================================================\n",
      "‚úÖ TASK 2 COMPLETED\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# # Task 2: Model Building - WORKING VERSION\n",
    "# \n",
    "# This notebook works with your file location.\n",
    "\n",
    "# %%\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Check where the file is\n",
    "print(\"Current directory:\", os.getcwd())\n",
    "print(\"\\nFiles in data/ directory:\")\n",
    "if os.path.exists('data'):\n",
    "    for item in os.listdir('data'):\n",
    "        item_path = os.path.join('data', item)\n",
    "        if os.path.isdir(item_path):\n",
    "            print(f\"üìÅ {item}/\")\n",
    "            for file in os.listdir(item_path):\n",
    "                print(f\"    {file}\")\n",
    "        else:\n",
    "            print(f\"üìÑ {item}\")\n",
    "\n",
    "# %%\n",
    "# Load the data from the correct location\n",
    "data_path = 'data/Fraud_Data.csv'  # Your actual location\n",
    "print(f\"\\nLoading data from: {data_path}\")\n",
    "\n",
    "df = pd.read_csv(\"../data/raw/Fraud_Data.csv\")\n",
    "print(f\"Data loaded: {df.shape}\")\n",
    "\n",
    "# %%\n",
    "# Basic preprocessing\n",
    "if 'signup_time' in df.columns:\n",
    "    df['signup_time'] = pd.to_datetime(df['signup_time'])\n",
    "if 'purchase_time' in df.columns:\n",
    "    df['purchase_time'] = pd.to_datetime(df['purchase_time'])\n",
    "    df['purchase_hour'] = df['purchase_time'].dt.hour\n",
    "    if 'signup_time' in df.columns:\n",
    "        df['hours_since_signup'] = (df['purchase_time'] - df['signup_time']).dt.total_seconds() / 3600\n",
    "        df['quick_purchase'] = (df['hours_since_signup'] < 1).astype(int)\n",
    "\n",
    "# Select features\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "features = [col for col in numeric_cols if col not in ['class', 'user_id']]\n",
    "\n",
    "X = df[features].fillna(0)\n",
    "y = df['class']\n",
    "\n",
    "print(f\"Features: {features}\")\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "print(f\"Fraud rate: {y.mean():.4%}\")\n",
    "\n",
    "# %%\n",
    "# Now run Task 2 models\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from src.task2_models import Task2Models\n",
    "\n",
    "trainer = Task2Models(random_state=42)\n",
    "\n",
    "# We already loaded X, y, so we can skip trainer.load_data()\n",
    "# Just use the prepare_data method\n",
    "X_train, X_test, y_train, y_test = trainer.prepare_data(X, y)\n",
    "\n",
    "print(f\"\\nTrain set: {X_train.shape}, fraud rate: {y_train.mean():.4%}\")\n",
    "print(f\"Test set: {X_test.shape}, fraud rate: {y_test.mean():.4%}\")\n",
    "\n",
    "# %%\n",
    "# 1. Baseline model\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"1. BASELINE MODEL - LOGISTIC REGRESSION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "baseline_results = trainer.train_baseline(X_train, y_train, X_test, y_test)\n",
    "\n",
    "# %%\n",
    "# 2. Ensemble model\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"2. ENSEMBLE MODEL - RANDOM FOREST\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "ensemble_results = trainer.train_ensemble(X_train, y_train, X_test, y_test, 'random_forest')\n",
    "\n",
    "# %%\n",
    "# 3. Cross-validation\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"3. 5-FOLD CROSS-VALIDATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for model_key, model in trainer.models.items():\n",
    "    model_name = trainer.results[model_key]['model_name']\n",
    "    cv_results = trainer.cross_validate(model, X, y, model_name)\n",
    "\n",
    "# %%\n",
    "# 4. Model comparison and selection\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"4. MODEL COMPARISON AND SELECTION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "best_model, best_name = trainer.compare_and_select()\n",
    "\n",
    "# %%\n",
    "# 5. Save best model\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"5. SAVE MODEL FOR TASK 3\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if best_model:\n",
    "    saved_path = trainer.save_model(best_model, best_name)\n",
    "    print(f\"\\n‚úÖ Best model saved to: {saved_path}\")\n",
    "    print(\"Ready for Task 3: Model Explainability\")\n",
    "\n",
    "# %%\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ TASK 2 COMPLETED\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece16aca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5d87cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4d1f27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
